"""
æ‰¹é‡ç”Ÿæˆ Plan A/B/C çš„å¯¹æ¯”å›¾
- é¢„æµ‹ç²¾åº¦åˆ†æï¼ˆå¾®è§‚è§†å›¾ + ç›¸å…³æ€§ï¼‰
- GOEè°±åˆ†æï¼ˆèƒ½çº§é—´è·ç»Ÿè®¡ + KSè·ç¦»ï¼‰
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from sympy import primerange
import os
from pathlib import Path

# ==================== é…ç½®åŒº ====================
WEIGHT_DIR = r"D:\pythonstudy\python_task\æƒé‡åˆ†æ"
OUTPUT_DIR = r"D:\pythonstudy\python_task\æƒé‡åˆ†æ\è®ºæ–‡å›¾ç‰‡"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# å®éªŒé…ç½®
EXPERIMENTS = {
    "Plan_A": {
        "weight_file": "Plan A.pt",
        "learnable_embedding": True,
        "label": "Plan A (Learnable + Large Batch)",
        "color": "#E74C3C"  # çº¢è‰²
    },
    "Plan_B": {
        "weight_file": "Plan B.pt",
        "learnable_embedding": True,
        "label": "Plan B (Learnable + Small Batch)",
        "color": "#3498DB"  # è“è‰²
    },
    "Plan_C": {
        "weight_file": "Plan C.pt",
        "learnable_embedding": False,  # æ­£å¼¦æ³¢ç¼–ç 
        "label": "Plan C (Sinusoidal + Large Batch)",
        "color": "#2ECC71"  # ç»¿è‰²
    }
}

# æ¨¡å‹å‚æ•°
D_MODEL = 256
N_LAYERS = 6
N_HEADS = 8
DROPOUT = 0.1
NUM_PRIMES = 1000000

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}\n")

# ==================== æ¨¡å‹å®šä¹‰ ====================
class RiemannEmbedding(nn.Module):
    def __init__(self, d_model, max_len=1000000, learnable=True):
        super().__init__()
        self.learnable = learnable
        if learnable:
            self.embedding = nn.Embedding(max_len, d_model)
        else:
            # æ­£å¼¦æ³¢ç¼–ç 
            pe = torch.zeros(max_len, d_model)
            position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
            div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))
            pe[:, 0::2] = torch.sin(position * div_term)
            pe[:, 1::2] = torch.cos(position * div_term)
            self.register_buffer('pe', pe)

    def forward(self, x):
        if self.learnable:
            return self.embedding(x)
        else:
            return self.pe[x]

class PrimeGapPredictor(nn.Module):
    def __init__(self, learnable_embedding=True):
        super().__init__()
        self.riemann_embedding = RiemannEmbedding(D_MODEL, NUM_PRIMES, learnable=learnable_embedding)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=D_MODEL,
            nhead=N_HEADS,
            dim_feedforward=D_MODEL*4,
            dropout=DROPOUT,
            batch_first=True,
            norm_first=True,
            activation='gelu'
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=N_LAYERS)
        self.output = nn.Sequential(
            nn.Linear(D_MODEL, D_MODEL // 2),
            nn.GELU(),
            nn.Dropout(DROPOUT),
            nn.Linear(D_MODEL // 2, D_MODEL // 4),
            nn.GELU(),
            nn.Dropout(DROPOUT),
            nn.Linear(D_MODEL // 4, 1)
        )

    def forward(self, x):
        embedded = self.riemann_embedding(x).unsqueeze(1)
        transformed = self.transformer(embedded)
        return self.output(transformed.squeeze(1))

# ==================== åˆ†æå‡½æ•° ====================

def load_model(weight_path, learnable_embedding):
    """åŠ è½½æ¨¡å‹"""
    model = PrimeGapPredictor(learnable_embedding=learnable_embedding).to(device)
    checkpoint = torch.load(weight_path, map_location=device, weights_only=False)
    state = checkpoint['model_state_dict'] if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint else checkpoint
    model.load_state_dict(state)
    model.eval()
    return model

def analyze_prediction_accuracy(model, plan_name, color):
    """é¢„æµ‹ç²¾åº¦åˆ†æï¼ˆå®Œå…¨ç…§æŠ„æºä»£ç ï¼‰"""
    print(f"  ğŸ” åˆ†æé¢„æµ‹ç²¾åº¦...")

    # ç”Ÿæˆå…¨éƒ¨ç´ æ•°å¹¶è®¡ç®—å…¨å±€ç»Ÿè®¡é‡
    all_primes = list(primerange(1, 18500000))[:NUM_PRIMES]
    all_gaps = np.diff(all_primes)

    global_mean = np.mean(all_gaps)
    global_std = np.std(all_gaps)

    # å–æœ€å1000ä¸ªgap
    total_gaps = len(all_gaps)
    target_len = 1000
    start_idx = total_gaps - target_len
    end_idx = total_gaps
    target_gaps = all_gaps[start_idx:end_idx]

    # é¢„æµ‹
    indices = torch.arange(start_idx, end_idx, device=device)
    with torch.no_grad():
        preds_norm = model(indices).squeeze().cpu().numpy()

    # è¿˜åŸå½’ä¸€åŒ–
    preds_real = (preds_norm * global_std) + global_mean

    # è®¡ç®—è¯¯å·®
    mae = np.mean(np.abs(preds_real - target_gaps))

    # ç»˜å›¾
    plt.figure(figsize=(18, 6))

    # å·¦å›¾ï¼šå¾®è§‚è§†å›¾ (å‰200ä¸ª)
    plt.subplot(1, 2, 1)
    plt.plot(target_gaps[:200], color='black', alpha=0.6, label='Real Truth', linewidth=2)
    plt.plot(preds_real[:200], color='red', alpha=0.8, linestyle='--', label='AI Prediction', linewidth=1.5)
    plt.title(f'Micro View: First 200 of Last 1000 Gaps')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # å³å›¾ï¼šæ•´ä½“ç›¸å…³æ€§
    plt.subplot(1, 2, 2)
    plt.scatter(target_gaps, preds_real, alpha=0.5, s=10, c='blue')
    min_v = min(target_gaps.min(), preds_real.min())
    max_v = max(target_gaps.max(), preds_real.max())
    plt.plot([min_v, max_v], [min_v, max_v], 'r--', label='Perfect Fit')
    plt.title(f'Correlation (MAE={mae:.4f})')
    plt.xlabel('Real Gap')
    plt.ylabel('Predicted Gap')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    save_path = os.path.join(OUTPUT_DIR, f'{plan_name}_prediction.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"    âœ… MAE = {mae:.4f}, å›¾ç‰‡å·²ä¿å­˜")
    return mae

def analyze_goe_spectrum(model, plan_name, color):
    """GOEè°±åˆ†æï¼ˆåŒ…å«KSè·ç¦»å’Œç›´æ–¹å›¾æ‹ŸåˆMAEï¼‰"""
    print(f"  ğŸ”¬ åˆ†æGOEè°±...")

    # æå–æƒé‡
    weights = []
    for name, param in model.named_parameters():
        if 'in_proj_weight' in name:
            weights.append(param.detach().cpu().numpy())

    if not weights:
        for name, param in model.named_parameters():
            if len(param.shape)==2 and param.shape[0]==param.shape[1]:
                weights.append(param.detach().cpu().numpy())

    if not weights:
        print("    âš ï¸ æœªæ‰¾åˆ°å¯ç”¨æƒé‡çŸ©é˜µ")
        return None

    # æ‹¼æ¥å¹¶æˆªå–ï¼ˆä¸¥æ ¼æŒ‰è®ºæ–‡æ–¹æ³•ï¼‰
    W_huge = np.concatenate(weights, axis=0)
    n = min(2048, W_huge.shape[0], W_huge.shape[1])
    W = W_huge[:n, :n]

    # å„ç±³åŒ–
    H = (W + W.T) / 2
    eigvals = np.linalg.eigvalsh(H)

    # è®¡ç®—èƒ½çº§é—´è·
    eigvals = np.sort(eigvals)
    limit_low = int(n * 0.15)
    limit_high = int(n * 0.85)
    eigvals = eigvals[limit_low : limit_high]
    spacings = np.diff(eigvals)
    s = spacings / np.mean(spacings)

    # ç»˜å›¾
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.hist(s, bins=70, density=True, alpha=0.65, color=color, edgecolor='black', label=f'AI Weights ({plan_name})')

    x = np.linspace(0, 4, 300)
    p_goe = (np.pi / 2) * x * np.exp(-np.pi * x**2 / 4)
    p_poisson = np.exp(-x)
    ax.plot(x, p_goe, 'r-', linewidth=3, label='GOE (Time-Reversal Symmetric Chaos)')
    ax.plot(x, p_poisson, 'g--', linewidth=3, label='Poisson (Random)')

    ax.set_title(f'{plan_name}: Level Spacing Statistics', fontsize=14, fontweight='bold')
    ax.set_xlabel('Normalized Spacing (s)', fontsize=12)
    ax.set_ylabel('Probability Density P(s)', fontsize=12)
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)
    ax.set_xlim(0, 3.5)

    plt.tight_layout()
    save_path = os.path.join(OUTPUT_DIR, f'{plan_name}_goe_spectrum.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

    # --- è®¡ç®—è·ç¦»æŒ‡æ ‡ ---
    # 1. ç›´æ–¹å›¾æ‹Ÿåˆ MAEï¼ˆåŸæ¥çš„æŒ‡æ ‡ï¼Œç°é‡å‘½åï¼‰
    def calc_pdf_mae(data, pdf_func):
        y_hist, bins = np.histogram(data, bins=100, density=True, range=(0, 3))
        centers = (bins[:-1] + bins[1:]) / 2
        return np.mean(np.abs(y_hist - pdf_func(centers)))

    mae_goe = calc_pdf_mae(s, lambda x: (np.pi / 2) * x * np.exp(-np.pi * x ** 2 / 4))
    mae_poisson = calc_pdf_mae(s, lambda x: np.exp(-x))

    # 2. çœŸå®çš„ Kolmogorov-Smirnov è·ç¦»
    def goe_cdf(s):
        return 1 - np.exp(-np.pi * s ** 2 / 4)

    def poisson_cdf(s):
        return 1 - np.exp(-s)

    s_valid = s[s <= 4]  # æ’é™¤è¿‡å¤§å€¼ï¼Œä¸å½±å“ KS ç»Ÿè®¡é‡
    ks_goe = stats.kstest(s_valid, goe_cdf).statistic
    ks_poisson = stats.kstest(s_valid, poisson_cdf).statistic

    # åŸºäº KS è·ç¦»çš„åˆ¤å†³ï¼ˆå“ªä¸ªæ›´å°ï¼‰
    verdict_ks = "GOE" if ks_goe < ks_poisson else "Poisson"

    print(f"    âœ… KS distance (vs GOE)     = {ks_goe:.4f}")
    print(f"       KS distance (vs Poisson) = {ks_poisson:.4f}")
    print(f"       MAE fit (vs GOE)         = {mae_goe:.4f} (nonâ€‘KS, legacy metric)")
    print(f"       MAE fit (vs Poisson)     = {mae_poisson:.4f}")

    return {
        "verdict": verdict_ks,  # æ”¹ç”¨ KS åˆ¤å†³
        "mae_goe": mae_goe,
        "mae_poisson": mae_poisson,
        "ks_goe": ks_goe,
        "ks_poisson": ks_poisson
    }
# ==================== ä¸»æµç¨‹ ====================

def main():
    print("="*60)
    print("ğŸš€ æ‰¹é‡ç”Ÿæˆ Plan A/B/C å¯¹æ¯”å›¾")
    print("="*60)

    results = {}

    for plan_name, config in EXPERIMENTS.items():
        print(f"\nğŸ“¦ å¤„ç† {plan_name}...")

        weight_path = os.path.join(WEIGHT_DIR, config["weight_file"])
        if not os.path.exists(weight_path):
            print(f"  âš ï¸ æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {weight_path}")
            continue

        print(f"  â³ åŠ è½½æƒé‡: {config['weight_file']}")
        model = load_model(weight_path, config["learnable_embedding"])

        mae = analyze_prediction_accuracy(model, plan_name, config["color"])
        goe_result = analyze_goe_spectrum(model, plan_name, config["color"])

        results[plan_name] = {
            "mae_pred": mae,
            "goe": goe_result
        }

    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š å®éªŒæ±‡æ€»")
    print("=" * 60)
    for plan_name, result in results.items():
        print(f"\nã€{plan_name}ã€‘")
        print(f"  é¢„æµ‹ç²¾åº¦: MAE = {result['mae_pred']:.4f}")
        if result['goe']:
            print(f"  GOEè°±åˆ†æ:")
            print(f"    - KS(GOE)     = {result['goe']['ks_goe']:.4f}")
            print(f"    - KS(Poisson) = {result['goe']['ks_poisson']:.4f}")
            print(f"    - MAE(GOE)     = {result['goe']['mae_goe']:.4f} (legacy)")
            print(f"    - MAE(Poisson) = {result['goe']['mae_poisson']:.4f} (legacy)")
            print(f"    åˆ¤å†³ (åŸºäºKS): {result['goe']['verdict']}")

if __name__ == "__main__":
    main()
